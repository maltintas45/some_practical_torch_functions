{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huggingface tokenizers of pretrained model such as BERT, ELECTRA, ALBERTO etc returns subword tokens that is not convenient some of problems that is each label assinged to word, not subword. You can do many different solution for this, but in this notebook we will do a solution using $gather$ function that is already implemented all common neural network freamworks. Thanks Mateusz Bednarski for clear explanation of $gather$ function on https://medium.com/analytics-vidhya/understanding-indexing-with-pytorch-gather-33717a84ebc4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T12:58:18.257176Z",
     "start_time": "2021-06-18T12:58:18.253626Z"
    }
   },
   "source": [
    "This study is coded using Torch but the required function $gather$ and $repeat$ is also avaible for Tensoflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T13:38:47.535079Z",
     "start_time": "2021-06-18T13:38:47.244399Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a dummy embedding tensor, It's dimension is batch_size x max_seq_lenght_according_to_subtoken_level x hidden_dim. You can look the given link for more detail about why created as an dummy tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T13:38:48.282403Z",
     "start_time": "2021-06-18T13:38:48.274929Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "max_seq_len = 9\n",
    "hidden_size = 6\n",
    "pretrained_embedings_on_subword_level = torch.empty(batch_size, max_seq_len, hidden_size)\n",
    "for i in range(batch_size):\n",
    "    for j in range(max_seq_len):\n",
    "        for k in range(hidden_size):\n",
    "            pretrained_embedings_on_subword_level[i,j,k] = i + j*10 + k*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T13:38:48.821001Z",
     "start_time": "2021-06-18T13:38:48.804072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0., 100., 200., 300., 400., 500.],\n",
       "         [ 10., 110., 210., 310., 410., 510.],\n",
       "         [ 20., 120., 220., 320., 420., 520.],\n",
       "         [ 30., 130., 230., 330., 430., 530.],\n",
       "         [ 40., 140., 240., 340., 440., 540.],\n",
       "         [ 50., 150., 250., 350., 450., 550.],\n",
       "         [ 60., 160., 260., 360., 460., 560.],\n",
       "         [ 70., 170., 270., 370., 470., 570.],\n",
       "         [ 80., 180., 280., 380., 480., 580.]],\n",
       "\n",
       "        [[  1., 101., 201., 301., 401., 501.],\n",
       "         [ 11., 111., 211., 311., 411., 511.],\n",
       "         [ 21., 121., 221., 321., 421., 521.],\n",
       "         [ 31., 131., 231., 331., 431., 531.],\n",
       "         [ 41., 141., 241., 341., 441., 541.],\n",
       "         [ 51., 151., 251., 351., 451., 551.],\n",
       "         [ 61., 161., 261., 361., 461., 561.],\n",
       "         [ 71., 171., 271., 371., 471., 571.],\n",
       "         [ 81., 181., 281., 381., 481., 581.]],\n",
       "\n",
       "        [[  2., 102., 202., 302., 402., 502.],\n",
       "         [ 12., 112., 212., 312., 412., 512.],\n",
       "         [ 22., 122., 222., 322., 422., 522.],\n",
       "         [ 32., 132., 232., 332., 432., 532.],\n",
       "         [ 42., 142., 242., 342., 442., 542.],\n",
       "         [ 52., 152., 252., 352., 452., 552.],\n",
       "         [ 62., 162., 262., 362., 462., 562.],\n",
       "         [ 72., 172., 272., 372., 472., 572.],\n",
       "         [ 82., 182., 282., 382., 482., 582.]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embedings_on_subword_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T12:05:56.206174Z",
     "start_time": "2021-06-18T12:05:56.200337Z"
    }
   },
   "source": [
    "Let's create a dummy offset tensor. It's dimension is batch_size x max_seq_according_to_token_level. We ignore some of subtokens, so we expect that max_seq_according_to_token_level<max_seq_lenght_according_to_subtoken_level x hidden_dim. We will get the first subtoken embeding here, you can modify it according to your request such as last subtoken, mean of subtoken etc. Note that if you want to get mean of subtoken embedings as a token embedding, so you may need also other fuctions such as $RaggedTensor$ (in Tensorflow) etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T13:38:49.937680Z",
     "start_time": "2021-06-18T13:38:49.932102Z"
    }
   },
   "outputs": [],
   "source": [
    "token_start_indexes = torch.tensor([[0,1,4,6,7],\n",
    "                                   [0,1,2,3,8],\n",
    "                                   [0,1,3,4,6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code lines do our aim successfully but it takes a bit time. We want to make it using $gather$ function to speed up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T13:38:51.214782Z",
     "start_time": "2021-06-18T13:38:51.211161Z"
    }
   },
   "outputs": [],
   "source": [
    "x=pretrained_embedings_on_subword_level[:, token_start_indexes]\n",
    "li=[x[i][i] for i,batch_i in enumerate(x)]\n",
    "pretrained_embedings_on_word_level_ref = torch.stack(li,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T13:38:51.997178Z",
     "start_time": "2021-06-18T13:38:51.988045Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0., 100., 200., 300., 400., 500.],\n",
       "         [ 10., 110., 210., 310., 410., 510.],\n",
       "         [ 40., 140., 240., 340., 440., 540.],\n",
       "         [ 60., 160., 260., 360., 460., 560.],\n",
       "         [ 70., 170., 270., 370., 470., 570.]],\n",
       "\n",
       "        [[  1., 101., 201., 301., 401., 501.],\n",
       "         [ 11., 111., 211., 311., 411., 511.],\n",
       "         [ 21., 121., 221., 321., 421., 521.],\n",
       "         [ 31., 131., 231., 331., 431., 531.],\n",
       "         [ 81., 181., 281., 381., 481., 581.]],\n",
       "\n",
       "        [[  2., 102., 202., 302., 402., 502.],\n",
       "         [ 12., 112., 212., 312., 412., 512.],\n",
       "         [ 32., 132., 232., 332., 432., 532.],\n",
       "         [ 42., 142., 242., 342., 442., 542.],\n",
       "         [ 62., 162., 262., 362., 462., 562.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embedings_on_word_level_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check your solution is right or not with this reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T12:13:58.390912Z",
     "start_time": "2021-06-18T12:13:58.387868Z"
    }
   },
   "source": [
    "To use gather we have to aware three parameter, \n",
    "- input : input tensor\n",
    "- dim     : dimension along to collect values\n",
    "- indices : tensor with indices of values to collect (it needs to be same dimension with input tensor except dim axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T13:38:53.755183Z",
     "start_time": "2021-06-18T13:38:53.748017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_start_indexes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T13:38:54.500685Z",
     "start_time": "2021-06-18T13:38:54.493392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 9, 6])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embedings_on_subword_level.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will collect our vector on dim 1, we will get the vector for the first subtokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T13:38:55.576252Z",
     "start_time": "2021-06-18T13:38:55.570869Z"
    }
   },
   "outputs": [],
   "source": [
    "#repeat 6 times\n",
    "batch_size, max_seq_according_to_token_level = token_start_indexes.shape \n",
    "indices = token_start_indexes.repeat(1,6).view(batch_size,-1,max_seq_according_to_token_level).transpose(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T13:38:56.243312Z",
     "start_time": "2021-06-18T13:38:56.235589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 6])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T13:38:56.743878Z",
     "start_time": "2021-06-18T13:38:56.736087Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1],\n",
       "         [4, 4, 4, 4, 4, 4],\n",
       "         [6, 6, 6, 6, 6, 6],\n",
       "         [7, 7, 7, 7, 7, 7]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1],\n",
       "         [2, 2, 2, 2, 2, 2],\n",
       "         [3, 3, 3, 3, 3, 3],\n",
       "         [8, 8, 8, 8, 8, 8]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1],\n",
       "         [3, 3, 3, 3, 3, 3],\n",
       "         [4, 4, 4, 4, 4, 4],\n",
       "         [6, 6, 6, 6, 6, 6]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T13:38:57.328191Z",
     "start_time": "2021-06-18T13:38:57.322924Z"
    }
   },
   "outputs": [],
   "source": [
    "pretrained_embedings_on_word_level = torch.gather(pretrained_embedings_on_subword_level,1,indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T13:38:58.104972Z",
     "start_time": "2021-06-18T13:38:58.099890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True]],\n",
       "\n",
       "        [[True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True]],\n",
       "\n",
       "        [[True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embedings_on_word_level_ref == pretrained_embedings_on_word_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, we have done it succesfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T13:15:38.443566Z",
     "start_time": "2021-06-18T13:15:38.437933Z"
    }
   },
   "source": [
    "Let's compare their speed on a huge tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T13:39:27.106671Z",
     "start_time": "2021-06-18T13:39:00.619053Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def operation_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "# dummy embedding tensor\n",
    "batch_size = 30000\n",
    "max_seq_len = 9\n",
    "hidden_size = 6\n",
    "pretrained_embedings_on_subword_level = torch.empty(batch_size, max_seq_len, hidden_size)\n",
    "for i in range(batch_size):\n",
    "    for j in range(max_seq_len):\n",
    "        for k in range(hidden_size):\n",
    "            pretrained_embedings_on_subword_level[i,j,k] = i + j*10 + k*100\n",
    "# dummy token start index tensor            \n",
    "token_start_indexes = torch.tensor([[0,1,4,6,7],\n",
    "                                   [0,1,2,3,8],\n",
    "                                   [0,1,3,4,6]])\n",
    "token_start_indexes = token_start_indexes.repeat(1,int(batch_size/3)).view(batch_size,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T13:39:27.447275Z",
     "start_time": "2021-06-18T13:39:27.343123Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 108000000000 bytes. Error code 12 (Cannot allocate memory)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8b1eae25c604>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrained_embedings_on_subword_level\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_start_indexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mli\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpretrained_embedings_on_word_level_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtoc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 108000000000 bytes. Error code 12 (Cannot allocate memory)\n"
     ]
    }
   ],
   "source": [
    "tic=time.time()\n",
    "x=pretrained_embedings_on_subword_level[:, token_start_indexes]\n",
    "li=[x[i][i] for i,batch_i in enumerate(x)]\n",
    "pretrained_embedings_on_word_level_ref = torch.stack(li,dim=0)\n",
    "toc=time.time()\n",
    "mins, secs = operation_time(tic, toc)\n",
    "print(f'Finished in {mins}m {secs}s without using gather function')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even it could not allocate memory on CPU for such a tensor. Using GPU also will not change the result of this race. Sorry, I could not test on GPU, because it is a bit busy now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T13:40:43.752750Z",
     "start_time": "2021-06-18T13:40:43.720086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 0m 0s with using gather function\n"
     ]
    }
   ],
   "source": [
    "tic=time.time()\n",
    "batch_size, max_seq_according_to_token_level = token_start_indexes.shape \n",
    "indices = token_start_indexes.repeat(1,6).view(batch_size,-1,max_seq_according_to_token_level).transpose(2,1)\n",
    "pretrained_embedings_on_word_level = torch.gather(pretrained_embedings_on_subword_level,1,indices)\n",
    "toc=time.time()\n",
    "mins, secs = operation_time(tic, toc)\n",
    "print(f'Finished in {mins}m {secs}s with using gather function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T13:40:44.897121Z",
     "start_time": "2021-06-18T13:40:44.880494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000e+00, 1.0000e+02, 2.0000e+02, 3.0000e+02, 4.0000e+02,\n",
       "          5.0000e+02],\n",
       "         [1.0000e+01, 1.1000e+02, 2.1000e+02, 3.1000e+02, 4.1000e+02,\n",
       "          5.1000e+02],\n",
       "         [4.0000e+01, 1.4000e+02, 2.4000e+02, 3.4000e+02, 4.4000e+02,\n",
       "          5.4000e+02],\n",
       "         [6.0000e+01, 1.6000e+02, 2.6000e+02, 3.6000e+02, 4.6000e+02,\n",
       "          5.6000e+02],\n",
       "         [7.0000e+01, 1.7000e+02, 2.7000e+02, 3.7000e+02, 4.7000e+02,\n",
       "          5.7000e+02]],\n",
       "\n",
       "        [[1.0000e+00, 1.0100e+02, 2.0100e+02, 3.0100e+02, 4.0100e+02,\n",
       "          5.0100e+02],\n",
       "         [1.1000e+01, 1.1100e+02, 2.1100e+02, 3.1100e+02, 4.1100e+02,\n",
       "          5.1100e+02],\n",
       "         [4.1000e+01, 1.4100e+02, 2.4100e+02, 3.4100e+02, 4.4100e+02,\n",
       "          5.4100e+02],\n",
       "         [6.1000e+01, 1.6100e+02, 2.6100e+02, 3.6100e+02, 4.6100e+02,\n",
       "          5.6100e+02],\n",
       "         [7.1000e+01, 1.7100e+02, 2.7100e+02, 3.7100e+02, 4.7100e+02,\n",
       "          5.7100e+02]],\n",
       "\n",
       "        [[2.0000e+00, 1.0200e+02, 2.0200e+02, 3.0200e+02, 4.0200e+02,\n",
       "          5.0200e+02],\n",
       "         [1.2000e+01, 1.1200e+02, 2.1200e+02, 3.1200e+02, 4.1200e+02,\n",
       "          5.1200e+02],\n",
       "         [4.2000e+01, 1.4200e+02, 2.4200e+02, 3.4200e+02, 4.4200e+02,\n",
       "          5.4200e+02],\n",
       "         [6.2000e+01, 1.6200e+02, 2.6200e+02, 3.6200e+02, 4.6200e+02,\n",
       "          5.6200e+02],\n",
       "         [7.2000e+01, 1.7200e+02, 2.7200e+02, 3.7200e+02, 4.7200e+02,\n",
       "          5.7200e+02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[2.9997e+04, 3.0097e+04, 3.0197e+04, 3.0297e+04, 3.0397e+04,\n",
       "          3.0497e+04],\n",
       "         [3.0007e+04, 3.0107e+04, 3.0207e+04, 3.0307e+04, 3.0407e+04,\n",
       "          3.0507e+04],\n",
       "         [3.0027e+04, 3.0127e+04, 3.0227e+04, 3.0327e+04, 3.0427e+04,\n",
       "          3.0527e+04],\n",
       "         [3.0037e+04, 3.0137e+04, 3.0237e+04, 3.0337e+04, 3.0437e+04,\n",
       "          3.0537e+04],\n",
       "         [3.0057e+04, 3.0157e+04, 3.0257e+04, 3.0357e+04, 3.0457e+04,\n",
       "          3.0557e+04]],\n",
       "\n",
       "        [[2.9998e+04, 3.0098e+04, 3.0198e+04, 3.0298e+04, 3.0398e+04,\n",
       "          3.0498e+04],\n",
       "         [3.0008e+04, 3.0108e+04, 3.0208e+04, 3.0308e+04, 3.0408e+04,\n",
       "          3.0508e+04],\n",
       "         [3.0028e+04, 3.0128e+04, 3.0228e+04, 3.0328e+04, 3.0428e+04,\n",
       "          3.0528e+04],\n",
       "         [3.0038e+04, 3.0138e+04, 3.0238e+04, 3.0338e+04, 3.0438e+04,\n",
       "          3.0538e+04],\n",
       "         [3.0058e+04, 3.0158e+04, 3.0258e+04, 3.0358e+04, 3.0458e+04,\n",
       "          3.0558e+04]],\n",
       "\n",
       "        [[2.9999e+04, 3.0099e+04, 3.0199e+04, 3.0299e+04, 3.0399e+04,\n",
       "          3.0499e+04],\n",
       "         [3.0009e+04, 3.0109e+04, 3.0209e+04, 3.0309e+04, 3.0409e+04,\n",
       "          3.0509e+04],\n",
       "         [3.0029e+04, 3.0129e+04, 3.0229e+04, 3.0329e+04, 3.0429e+04,\n",
       "          3.0529e+04],\n",
       "         [3.0039e+04, 3.0139e+04, 3.0239e+04, 3.0339e+04, 3.0439e+04,\n",
       "          3.0539e+04],\n",
       "         [3.0059e+04, 3.0159e+04, 3.0259e+04, 3.0359e+04, 3.0459e+04,\n",
       "          3.0559e+04]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embedings_on_word_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$gather$ won! ;) Thanks for your attention. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alp",
   "language": "python",
   "name": "alp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
